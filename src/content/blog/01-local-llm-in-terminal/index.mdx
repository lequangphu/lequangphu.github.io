---
title: "Terminal + LLM: from Warp to Ghostty"
description: "How I replace Warp with Ghostty."
date: "Oct 11 2025"
---

import { Tweet } from 'astro-embed';

I am using aichat and a local LLM inside Ghostty to replace Warp. Why?
- Warp's app icon is ugly, and Ghostty's app icon is beautiful.
- I challenge myself to work with a local LLM instead of a free version of a paid LLM product. I have to connect the local LLM to Ghostty via aichat.

At the time of writing, the local LLM is qwen3-4b-2507 served by LM Studio. The model is the best among models of its size for me.
I used Grok (x.ai) to install Ghostty, aichat (rustup + cargo), and LM Studio.
I recommend model configs as below.

![Model configs](/Screenshot%202025-10-11%20at%2023.34.10.JPG)

6 bits quantization is recommended by an Apple's staff working on their AI.

<Tweet id="https://x.com/awnihannun/status/1977024847462252713" />